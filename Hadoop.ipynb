{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop Platform\n",
    "\n",
    "## Week 1 - Hadoop Basics\n",
    "\n",
    "### Hadoop stack basics\n",
    "- open stack framework - plug in tools\n",
    "- large scale storage and processing\n",
    "- clusters\n",
    "- Doug Cutting + Mike Cafarella 2005 (Yahoo, Cloudera)\n",
    "- named after toy elephant\n",
    "- batch processing, MapReduce\n",
    "- simple, powerful, v. efficient\n",
    "- **move computation to data**\n",
    "- **scalability at its core**\n",
    "    * distrubuted\n",
    "    * cheap hardware\n",
    "- reliability\n",
    "- HDFS (based on Google file system)\n",
    "- schema-on-read (project into schema on the fly)\n",
    "- new kinds of analysis -- more data, simple analytics better result than small data, complex analytics (more granularity)\n",
    "\n",
    "\n",
    "### Basic components\n",
    "1. Hadoop common\n",
    "2. HDFS (Hadoop Distributed File System)\n",
    "3. YARN -- resource manager\n",
    "4. MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Hadoop ecosystem](hadoop_ecosystem.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hadoop high level architecture](hadoop_high_level_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hadoop Distributed File System (HDFS)\n",
    "- distributed, scalable, portable file system written in Java for Hadoop\n",
    "- Namenode holds metadata + datanodes cluster\n",
    "- stores large data files across multiple machines and replicates data for reliability (so no need for RAID redundant array of inexpensive/independent disks)\n",
    "![HDFS architecture](hdfsarchitecture.gif)\n",
    "- Secondary NameNode takes snapshots of NameNodes metadata\n",
    "![NameNode](namenode.png)\n",
    "- some version of a MapReduce sits on top, and consists of:\n",
    "    * A job tracker - sits on Master\n",
    "    * A task tracker - sits on nodes/slaves\n",
    "![Jobs and Tasks](hadoop_jobs-tasks.png)\n",
    "- MRV2 - MapReduce V2 --> **YARN**: split resource management (scheduling) and map reduce into two seaparate daemons\n",
    "    * scalability\n",
    "    * map reduce compatibility\n",
    "    * improved cluster utilization:\n",
    "        * capacity, \n",
    "        * guarantees, \n",
    "        * fairness, \n",
    "        * slas, \n",
    "        * supports other workloads (not just MapReduce) e.g. machine learning\n",
    "        * multiple access engines - batch, streaming\n",
    "![YARN](yarn1.gif)\n",
    "![MRV2](yarn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Zoo\" / Hadoop ecosystem major components\n",
    "![Cloudera's distribution with Hadoop](Cloudera.png)\n",
    "- can be run as a VM or you can log in to Cloudera\n",
    "\n",
    "#### Apache Sqoop \n",
    "- \"SQL to Hadoop\"\n",
    "- tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases\n",
    "- command line tool \n",
    "- import individual tables or entire databases\n",
    "- generates java classes that allow us to interact with imported data\n",
    "- ability to import SQL databases straight into Hive\n",
    "- set up an import job and scoop\n",
    "\n",
    "#### HBase\n",
    "- column-oriented database management system\n",
    "- key-value store\n",
    "- based on Google Bigtable\n",
    "- holds extremely large data\n",
    "- dynamic data model, not RDBMS\n",
    "\n",
    "#### Pig\n",
    "- scripting language - high level programming on top of Hadoop MapReduce\n",
    "- Pig Latin\n",
    "- Data analysis problems as data flows\n",
    "- orig. devp'd Yahoo 2006\n",
    "- languages include JRuby, JPython and Java\n",
    "- can run pig scripts in other languages\n",
    "- Pig for ETL - extract, transform according to rules, load into a data store via UDF (user defined functions)\n",
    "\n",
    "#### Hive\n",
    "- data warehouse software factilities querying and managing large datasets residing in distributed storage\n",
    "- projects structure on top of all of this data and allows us to use SQL Like queries (HiveQL)\n",
    "- can also plug in MapReduce if the query would too be complex\n",
    "\n",
    "#### Oozie\n",
    "- workflow scheduler system to manage Hadoop jobs\n",
    "- oozie workflow jobs are DAGs (Directed, acycling graphs)\n",
    "- oozie coordinator jobs are recurrent oozie workflow jobs that are triggered by frequency or data availability\n",
    "- supports: mapreduce (batch, streaming), pig, hive, sqoop, etc\n",
    "- very scalable and reliable, and extensible\n",
    "\n",
    "#### Zookeeper\n",
    "- provides operational services for a hadoop cluster\n",
    "- centralized service for maintaining config info, naming, providing distributed synchronization \n",
    "- distributed configuration service, job sychronisation service, and a naming registry for the entire distributed system\n",
    "- distributed systems use zookeeper to store updates to important config info on the cluster itself\n",
    "\n",
    "#### Flume\n",
    "- distributed, reliable and available service for efficiently collecting, aggregating and moving large amounts of data\n",
    "- simple and flexible architecture based on streaming data flows\n",
    "- robust, fault tolerant\n",
    "- tunable to enhanced reliability mechanisms, fail over, recovery --> keep cluster safe and reliable\n",
    "- uses simple extensible data model that allows us to apply all kinds of online analytic applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring the Cloudera VM\n",
    "\n",
    "Follow the included tutorial at http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cloudera_quickstart_vm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Introduction to the Hadoop stack\n",
    "\n",
    "### Overview of the Hadoop stack\n",
    "\n",
    "#### Basic Hadoop components\n",
    "* Hadoop common - libraries and utilities (foundation on top of which everything is built)\n",
    "* HDFS - distributed file system - the storage underpining the Hadoop instance\n",
    "* YARN - resource management platform, scheduling\n",
    "* MapReduce - a programming model for large scale data processing\n",
    "\n",
    "#### Hadoop 1.0 to 2.0 transition \n",
    "- the introduction of YARN, splitting resource management and MapReduce/processing\n",
    "![Hadoop transition](hadoop_transition.png)\n",
    "- Tez is one option for execution management (sits above YARN, with applications like MR, Pig, Hive, etc sitting on top of Tez)\n",
    "\n",
    "#### Applications and Frameworks\n",
    "* **HBase** - a scalable data warehouse with support for large tables\n",
    "* **Hive** - a data warehouse infrastructure that provides data summarization and ad hoc querying\n",
    "* **PIg** - a high level data-flow language and execution framework for parallel computation\n",
    "* **Spark** - a fast and general compute engine for Hadoop data. Wide range of applications - ETL, Machine Learning, stream processing, and graph analytics\n",
    "\n",
    "Above the YARN layer you could have Tez execution engine, Spark, as well as applications that work directly with YARN e.g. Impala\n",
    "\n",
    "#### HDFS and HDFS2\n",
    "- design concepts and goals\n",
    "    - *Concepts*\n",
    "        * blocks of data spread out over many nodes enhances capacity\n",
    "        * scalable distributed file system\n",
    "        * distribute data on local disks on several nodes\n",
    "        * low cost commodity hardware\n",
    "    - *goals*\n",
    "        * resilience (Failure recovery)\n",
    "        * scalable (many nodes + namespace)\n",
    "        * application locality (move app to data)\n",
    "        * portability (generalised works on all platforms)\n",
    "- HDFS architecture (to meet these design goals)\n",
    "    * *NameNode* (metadata) and many *DataNodes*, with clients that read/write and data replicated across nodes\n",
    "    * *NameNode* holds metadata - \"data about data\" information about the filesystem state, block information, edit and transaction information and locks\n",
    "- enhancements in next gen HDFS (HDFS2 came with Hadoop 2.0)\n",
    "    * original hdfs design\n",
    "        - single namenode (option for standby namenode)\n",
    "        - multiple datanodes\n",
    "            - manage storage - blocks of data\n",
    "            - serving r/w requests from clients\n",
    "            - block creation, deletion and replication\n",
    "     * HDFS2\n",
    "         - HDFS federation\n",
    "             - multiple datanodes under multiple namenodes\n",
    "             - benefits:\n",
    "                 * increased namespace scalability\n",
    "                 * performance\n",
    "                 * isolation e.g. intensive, expensive operations won't have an impact on whole system\n",
    "                 \n",
    "             - how done?\n",
    "                 * multiple namenode servers\n",
    "                 * multiple namespaces\n",
    "                 * block pools\n",
    "         - high availability w. redundant namenodes\n",
    "         - heterogeneous storage and archival storage: archive, disk, ssd, ram_disk\n",
    "![Federation](federation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MapReduce framework and YARN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
